{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e7adbc7-2472-43bd-b03f-3f36d73184ea",
   "metadata": {},
   "source": [
    "## CAPAS en Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625e250e-3703-4f1b-954d-bbdc0dc9c031",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## capa batchnormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f638a1-3f97-4965-9c23-da93b2f4e16e",
   "metadata": {},
   "source": [
    "La capa de Normalización por Lotes (Batch Normalization) en una red neuronal tiene varias funciones importantes que mejoran el proceso de entrenamiento:\n",
    "\n",
    "- Reducción del problema del cambio de covariables: Durante el entrenamiento de una red neuronal profunda, los parámetros de las capas anteriores cambian, lo que puede llevar a cambios en la distribución de las entradas a las capas siguientes. Este fenómeno se conoce como cambio de covariables. La Normalización por Lotes ayuda a mitigar este problema al estandarizar (es decir, hacer que la media sea 0 y la varianza sea 1) las entradas de cada mini-lote.\n",
    "\n",
    "- Permite tasas de aprendizaje más altas: Al normalizar las entradas, se estabilizan y se reducen los cambios en la distribución de las activaciones a lo largo del entrenamiento, lo que puede permitir tasas de aprendizaje más altas sin correr el riesgo de divergencia.\n",
    "\n",
    "- Regularización: La Normalización por Lotes añade un ligero efecto de regularización al modelo. Durante el entrenamiento, al calcular la media y la varianza de un mini-lote, se introduce cierto ruido en la propagación hacia adelante (forward propagation). Este ruido puede tener un efecto regularizador similar al del Dropout, aunque no debe ser considerado como un sustituto completo de las técnicas de regularización.\n",
    "\n",
    "- Reduce la necesidad de inicializaciones muy precisas: Dado que la normalización estabiliza las activaciones, el modelo es menos sensible a la inicialización de los pesos.\n",
    "\n",
    "- Puede acelerar la convergencia del entrenamiento: Al reducir los problemas mencionados anteriormente, la Normalización por Lotes a menudo resulta en un entrenamiento más rápido, es decir, se requiere un menor número de épocas para alcanzar un nivel de error similar o menor.\n",
    "\n",
    "En el modelo proporcionado, la capa BatchNormalization se aplica después de las capas Dense y Dropout. Esto significa que antes de pasar a la siguiente capa Dense, la salida de la capa anterior se normaliza. Esto es particularmente útil después de las capas Dropout, ya que el Dropout puede alterar la media y la varianza de la salida durante el entrenamiento debido a la desactivación aleatoria de neuronas.\n",
    "\n",
    "Es importante mencionar que la Normalización por Lotes tiene hiperparámetros que se pueden ajustar, como el momentum y los términos beta y gamma que se pueden aprender. Además, durante el entrenamiento se calculan la media y la varianza del mini-lote, mientras que durante la inferencia se utilizan la media y la varianza acumuladas de los mini-lotes del entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2370dc1-96e2-49e3-a351-8abe5c08581e",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "def create_model():\n",
    "    Input_ = tf.keras.Input(shape=(84,))\n",
    "    model = tf.keras.layers.Dense(128, activation=tf.nn.relu)(Input_)\n",
    "    model = tf.keras.layers.Dropout(0.4)(model)\n",
    "    model = tf.keras.layers.BatchNormalization()(model)\n",
    "\n",
    "    model = tf.keras.layers.Dense(64, activation=tf.nn.relu)(model)\n",
    "    model = tf.keras.layers.Dropout(0.4)(model)\n",
    "    model = tf.keras.layers.BatchNormalization()(model)\n",
    "\n",
    "    model = tf.keras.layers.Dense(8, activation=tf.nn.softmax)(model)\n",
    "    return tf.keras.Model(inputs=Input_, outputs=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7473c06d-be5d-4de5-b0b7-f2e3b5c1c678",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## convolucional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18892d01-6e31-4c20-ba85-509e41a8fc5c",
   "metadata": {},
   "source": [
    "This layer creates a convolution kernel that is convolved with the layer input over a single spatial (or temporal) dimension to produce a tensor of outputs. If use_bias is True, a bias vector is created and added to the outputs. Finally, if activation is not None, it is applied to the outputs as well.\n",
    "\n",
    "Esta capa crea un núcleo(kernel) de convolución que convoluciona con la entrada de la capa en una única dimensión espacial (o temporal) para producir un tensor de salidas. Si use_bias es True, se crea un vector de polarización y se agrega a las salidas. Finalmente, si la activación no es Ninguna, se aplica también a las salidas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a34d92-e36d-453a-aa10-60ed4253a24a",
   "metadata": {},
   "source": [
    "Imagina que tienes una fila de fichas de dominó y quieres encontrar patrones interesantes en esas fichas. Cada ficha de dominó es como un valor en tu serie de datos, y quieres ver si hay ciertos patrones dentro de esa fila de fichas.\n",
    "\n",
    "La \"capa de convolución\" es como una pequeña ventana que colocas sobre un grupo de fichas de dominó a la vez.\n",
    "\n",
    "El \"filtro\" es como una regla especial que utilizas para buscar patrones específicos en ese grupo de fichas.\n",
    "\n",
    "El \"strides\" (paso) es cuántas fichas de dominó avanzas cada vez que mueves la ventana.\n",
    "\n",
    "Si usas sesgos (\"use_bias\"), es como agregar un número extra que afecta cada vez que encuentras un patrón interesante.\n",
    "\n",
    "La \"función de activación\" es como una forma especial en la que decides cómo interpretar los patrones que encuentras. Por ejemplo, podrías decidir si un patrón es relevante o no.\n",
    "\n",
    "Entonces, la capa de convolución toma tu fila de fichas de dominó (tus datos de entrada), coloca una ventana sobre un grupo de fichas a la vez, busca patrones usando un filtro especial, avanza cierto número de fichas cada vez, opcionalmente agrega un número extra (sesgo), y finalmente decide cómo interpretar esos patrones usando una función especial.\n",
    "\n",
    "Esto es lo que hace la capa de convolución en términos simples: busca patrones en tus datos y los interpreta de una manera específica para obtener una salida."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd965cb7-9097-4d2a-81d2-47fe6f0f57eb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Maxpooling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1a25bc-f3d3-4ce9-98c6-e17d099556f5",
   "metadata": {},
   "source": [
    "Downsamples the input representation by taking the maximum value over a spatial window of size pool_size. The window is shifted by strides. The resulting output, when using the \"valid\" padding option, has a shape of: output_shape = (input_shape - pool_size + 1) / strides)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa6185e-caa9-47f1-bc85-e32de17a4619",
   "metadata": {},
   "source": [
    "Imagina que tienes una hoja de papel cuadriculada con números en cada casilla, y quieres reducir la cantidad de información manteniendo solo los números más grandes en un área rectangular.\n",
    "\n",
    "Input (Entrada): La hoja de papel cuadriculada con números es como tu conjunto de datos de entrada.\n",
    "\n",
    "pool_size (Tamaño de la Ventana): La ventana rectangular que mueves por la hoja es como el parámetro pool_size, que especifica el tamaño de la ventana que usarás para encontrar los números más grandes.\n",
    "\n",
    "strides (Paso): La cantidad de casillas que avanzas cada vez que mueves la ventana es como el parámetro strides. Determina cuánto te desplazas para encontrar los números más grandes.\n",
    "\n",
    "Padding (Relleno): Hay dos opciones comunes aquí:\n",
    "\n",
    "\"Valid\": Significa que solo moverás la ventana dentro del papel cuadriculado y no permitirás que la ventana se salga del borde. Esto da como resultado una hoja de papel más pequeña.\n",
    "\"Same\": Significa que permitirás que la ventana se salga del borde si es necesario para que todos los números tengan la oportunidad de ser seleccionados. Esto da como resultado una hoja de papel del mismo tamaño.\n",
    "Output (Salida): La nueva hoja de papel con números más grandes que obtienes después de mover la ventana se parece a la salida de la operación de agrupación (pooling).\n",
    "\n",
    "output_shape (Forma de la Salida): La forma o el tamaño de la nueva hoja de papel (output_shape) depende de cómo configures los parámetros. Si usas \"Valid\", la nueva hoja será más pequeña y su tamaño se calculará como (tamaño de entrada - tamaño de la ventana + 1) / paso. Si usas \"Same\", la nueva hoja tendrá el mismo tamaño que la original, y su tamaño se calculará como tamaño de entrada / paso.\n",
    "\n",
    "En resumen, la operación de \"pooling\" es como mover una ventana sobre tus datos, seleccionando los valores más grandes en esa ventana y creando una versión resumida de tus datos en función de esos valores seleccionados. El tamaño de la ventana y cómo te mueves a través de tus datos (strides) afectan la forma y el tamaño de la versión resumida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1a39575-efcb-4ba1-a1d7-f21ad3d354b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 4, 1), dtype=float32, numpy=\n",
       "array([[[2.],\n",
       "        [3.],\n",
       "        [4.],\n",
       "        [5.]]], dtype=float32)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "x = tf.constant([1., 2., 3., 4., 5.])\n",
    "x = tf.reshape(x, [1, 5, 1])\n",
    "max_pool_1d = tf.keras.layers.MaxPooling1D(pool_size=2,\n",
    "   strides=1, padding='valid')\n",
    "max_pool_1d(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32dcc14-f96d-4b9b-b88d-37b39cd4b3e3",
   "metadata": {},
   "source": [
    " este ejemplo utiliza una capa de MaxPooling 1D en TensorFlow. El MaxPooling 1D es una operación que se utiliza comúnmente en redes neuronales convolucionales (CNNs) para reducir el tamaño de las características y resaltar características importantes en una secuencia unidimensional de datos, como una serie de tiempo o una señal.\n",
    "\n",
    "Aquí está el desglose del código:\n",
    "\n",
    "x = tf.constant([1., 2., 3., 4., 5.]): Aquí se crea un tensor unidimensional x con los valores [1.0, 2.0, 3.0, 4.0, 5.0]. Este tensor representa una secuencia de datos.\n",
    "\n",
    "x = tf.reshape(x, [1, 5, 1]): Se cambia la forma del tensor x de [1, 5] a [1, 5, 1]. Esto significa que ahora tenemos una secuencia unidimensional con una dimensión extra de tamaño 1. Esta es la forma que MaxPooling 1D espera.\n",
    "\n",
    "max_pool_1d = tf.keras.layers.MaxPooling1D(pool_size=2, strides=1, padding='valid'): Aquí se crea una capa de MaxPooling 1D con los siguientes parámetros:\n",
    "\n",
    "pool_size=2: El tamaño de la ventana de agrupación es 2. Esto significa que la ventana se deslizará sobre la secuencia tomando grupos de 2 elementos a la vez.\n",
    "strides=1: El paso o desplazamiento de la ventana es 1. Esto significa que la ventana se mueve una posición a la vez a lo largo de la secuencia.\n",
    "padding='valid': No se agrega ningún relleno alrededor de la secuencia.\n",
    "max_pool_1d(x): Finalmente, se aplica la capa de MaxPooling 1D al tensor x. La capa realiza la operación de agrupación máxima en la secuencia utilizando la ventana de tamaño 2 y el desplazamiento de 1. El resultado es una versión reducida de la secuencia original, donde se toma el valor máximo en cada ventana de 2 elementos.\n",
    "\n",
    "El resultado de max_pool_1d(x) será una secuencia más corta, ya que la operación de agrupación máxima reduce la longitud de la secuencia en función de la ventana y el paso especificados. El resultado será una versión resumida de la secuencia original con los valores máximos en cada ventana de 2 elementos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5034bc-28fc-4539-9f3f-d46fc1dc3324",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Flatten"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1271fcac-635a-47d3-bb7c-8af90b06bf39",
   "metadata": {},
   "source": [
    "\n",
    "El uso de flatten en este ejemplo está relacionado con la arquitectura de una red neuronal convolucional (CNN) y cómo se manejan las dimensiones de los datos dentro de la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7da715c-6913-4447-a9a0-7247a2de24dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(64, 3, 3, input_shape=(3, 32, 32)))\n",
    "model.output_shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14013f5-283e-4baa-9baf-665b0a48754a",
   "metadata": {},
   "source": [
    "En este código, estás construyendo un modelo de CNN utilizando TensorFlow y Keras. La capa que se agrega es una capa de convolución 2D (Conv2D). Esta capa se utiliza comúnmente para procesar imágenes o datos con dos dimensiones espaciales, como imágenes con altura y ancho.\n",
    "\n",
    "tf.keras.layers.Conv2D(64, 3, 3, input_shape=(3, 32, 32)): Esta línea de código agrega una capa de convolución 2D al modelo con 64 filtros, un tamaño de kernel de 3x3 y una forma de entrada (input_shape) de (3, 32, 32). Aquí, 3 se refiere a los canales de color (por ejemplo, rojo, verde y azul en una imagen RGB), y 32x32 es el tamaño de la imagen.\n",
    "Ahora, hablemos de la capa flatten y por qué se utiliza:\n",
    "\n",
    "Después de aplicar una o varias capas de convolución y posiblemente capas de agrupación (pooling), es común que la salida de estas capas tenga una estructura tridimensional (alto x ancho x canales). Sin embargo, antes de pasar esta salida a capas completamente conectadas (como capas densas) para realizar tareas de clasificación, es necesario \"aplanar\" los datos.\n",
    "\n",
    "La capa flatten se utiliza para convertir esta salida tridimensional en un vector unidimensional. Esto se hace tomando todos los valores de la salida y colocándolos uno al lado del otro en un solo vector. Esta operación de aplanamiento asegura que los datos estén en el formato adecuado para las capas densas que siguen, ya que las capas densas esperan datos unidimensionales.\n",
    "\n",
    "Por lo tanto, en este ejemplo, la capa flatten se usa para convertir la salida de la capa de convolución 2D en un vector unidimensional antes de continuar con capas adicionales en el modelo. Esto es necesario para que las operaciones de clasificación posterior funcionen correctamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1b85d4-17c8-42b9-a0b8-b198937f86e7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## uso de las capas convolucionales y las maxpooling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed40e90e-9b72-4210-b41c-d81e0db6475c",
   "metadata": {
    "tags": []
   },
   "source": [
    "Las capas de convolución (Convolutional Layers) y las capas de MaxPooling (MaxPooling Layers) son componentes esenciales en una red neuronal convolucional (CNN), pero tienen propósitos y funciones diferentes en el procesamiento de imágenes y datos espaciales. Aquí te explico cómo se diferencian:\n",
    "\n",
    "\n",
    "##### **Capas de Convolución (Convolutional Layers)**:\n",
    "\n",
    "Operación de Convolución: Las capas de convolución aplican operaciones de convolución a la entrada. **La convolución es una operación matemática que involucra un filtro (también llamado kernel) que se desliza sobre la entrada para extraer características locales.**\n",
    "Aprendizaje de Características: Las capas de convolución aprenden automáticamente las características y patrones relevantes en los datos, como bordes, texturas o formas, mediante el ajuste de los valores de los filtros durante el entrenamiento.\n",
    "Salida de 3D a 3D: La salida de una capa de convolución conserva una estructura tridimensional, donde las dimensiones representan el alto, el ancho y los canales (por ejemplo, canales de color en una imagen).\n",
    "Reducción de Dimensiones: A menudo, se utilizan capas de convolución para reducir gradualmente las dimensiones espaciales (alto y ancho) de la entrada mediante el uso de varios filtros.\n",
    "##### **Capas de MaxPooling (MaxPooling Layers)**:\n",
    "\n",
    "Operación de MaxPooling: Las capas de MaxPooling aplican una operación de agrupación máxima a la entrada. En lugar de aprender características, su función principal es reducir la dimensionalidad de la entrada seleccionando el valor máximo en ventanas de la entrada.\n",
    "Agregación de Información: MaxPooling reduce la cantidad de informaciónaa manteniendo solo los valores máximos en ventanas deslizantes. Esto resalta las características más importantes y reduce el costo computacional.\n",
    "Salida de 3D a 3D: Similar a las capas de convolución, las capas de MaxPooling conservan una estructura tridimensional en la salida, manteniendo los canales de entrada.\n",
    "Reducción de Dimensiones: MaxPooling se utiliza comúnmente para reducir las dimensiones espaciales de una representación sin perder información crítica.\n",
    "Diferencia clave: Las capas de convolución se centran en aprender características y patrones, mientras que las capas de MaxPooling se utilizan principalmente para reducir la dimensionalidad y mejorar la eficiencia computacional.\n",
    "\n",
    "En una CNN típica, estas capas se suelen combinar en múltiples etapas. Las capas de convolución extraen características, y las capas de MaxPooling reducen las dimensiones de esas características, lo que permite que la red aprenda jerarquías de características cada vez más abstractas a medida que se profundiza en la red."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33eceab6-0aae-4bd0-b4f7-6fb480598a89",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1529c5af-924b-4442-a3f1-9e57f32f353c",
   "metadata": {},
   "source": [
    "Imagina una red neuronal LSTM (Long Short-Term Memory) como una libreta con hojas de papel, donde cada página representa una \"celda de memoria\" y cada celda puede escribir, leer y borrar información a lo largo del tiempo. Esta libreta se utiliza para recordar y procesar secuencias de eventos de manera eficiente, como entender una conversación o predecir el siguiente paso en una serie temporal.\n",
    "\n",
    "Aquí tienes una analogía paso a paso:\n",
    "\n",
    "Hoja de Papel Especial: La libreta tiene hojas de papel especiales llamadas celdas de memoria LSTM. Cada celda puede guardar información de forma temporal y tiene tres partes esenciales: un bolígrafo para escribir información, un lector para leer lo que está escrito y una goma de borrar para borrar información cuando ya no es necesaria.\n",
    "\n",
    "Secuencia de Eventos: Imagina que estás escuchando una conversación que se desarrolla a lo largo del tiempo o estás siguiendo una serie de números en una secuencia temporal, como los precios de las acciones en la bolsa.\n",
    "\n",
    "Escribir y Recordar: Cuando llega un nuevo evento en la secuencia, usas el bolígrafo de la celda de memoria LSTM para escribir información sobre ese evento en una página de la libreta. Por ejemplo, podrías escribir detalles sobre lo que se dijo en la conversación o el valor actual de una acción.\n",
    "\n",
    "Leer y Usar: Cuando necesitas tomar una decisión o comprender la secuencia de eventos, utilizas el lector de la celda LSTM para leer lo que has escrito en las páginas anteriores. Esto te permite tener en cuenta eventos pasados para tomar decisiones informadas.\n",
    "\n",
    "Borrar y Olvidar: A medida que avanzas en la secuencia temporal, algunos eventos pueden volverse menos relevantes. Aquí es donde entra en juego la goma de borrar de la celda LSTM. Puedes borrar información que ya no es importante para liberar espacio en la memoria y mantener solo lo esencial.\n",
    "\n",
    "Conexión de Páginas: Las celdas de memoria LSTM están conectadas en una secuencia, de modo que lo que escribas en una página puede afectar lo que escribas en la siguiente. Esto te permite capturar relaciones y patrones complejos entre eventos a lo largo del tiempo.\n",
    "\n",
    "Aprendizaje: A medida que continúas usando la libreta con celdas LSTM en varias secuencias de eventos, la libreta \"aprende\" a identificar patrones, recordar información relevante y olvidar lo que no es importante. Esta capacidad de aprender y adaptarse es lo que hace que las LSTM sean poderosas para tareas como el procesamiento del lenguaje natural o la predicción de series temporales.\n",
    "\n",
    "En resumen, una red neuronal LSTM funciona como una libreta de celdas de memoria especializadas que pueden escribir, leer y borrar información a lo largo del tiempo para procesar secuencias de eventos y capturar relaciones complejas en datos secuenciales. Esta analogía puede ayudarte a comprender cómo estas redes neuronales gestionan la información en tareas que implican datos temporales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c586d5-f627-4b48-919d-676e6555f524",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.random.normal([32, 10, 8])\n",
    "lstm = tf.keras.layers.LSTM(4)\n",
    "output = lstm(inputs)\n",
    "print(output.shape)\n",
    "\n",
    "lstm = tf.keras.layers.LSTM(4, return_sequences=True, return_state=True)\n",
    "whole_seq_output, final_memory_state, final_carry_state = lstm(inputs)\n",
    "print(whole_seq_output.shape)\n",
    "\n",
    "print(final_memory_state.shape)\n",
    "\n",
    "print(final_carry_state.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6323ca-b7e8-4e68-a7d8-faf06d0babcc",
   "metadata": {},
   "source": [
    "Este ejemplo utiliza la capa LSTM (Long Short-Term Memory) de TensorFlow para procesar una secuencia de datos. Aquí está el análisis paso a paso:\n",
    "\n",
    "1. Creación de Datos de Entrada:\n",
    "\n",
    "inputs = tf.random.normal([32, 10, 8]): Aquí se crea un tensor llamado inputs que contiene datos aleatorios. El tensor tiene una forma de [32, 10, 8], lo que significa lo siguiente:\n",
    "- 32 representa el tamaño del lote (batch size), es decir, hay 32 secuencias de datos independientes.\n",
    "- 10 representa la longitud de cada secuencia, lo que significa que cada secuencia tiene 10 pasos de tiempo.\n",
    "- 8 representa la dimensión de cada paso de tiempo, lo que indica que en cada paso de tiempo hay 8 valores o características.\n",
    "\n",
    "2. Creación de una Capa LSTM sin return_sequences:\n",
    "\n",
    "lstm = tf.keras.layers.LSTM(4): Se crea una capa LSTM que tiene 4 unidades (neuronas) en cada celda LSTM. No se establece \n",
    "return_sequences=True, lo que significa que la capa LSTM solo devolverá la salida correspondiente al último paso de tiempo de cada secuencia en el lote. Esta configuración es útil cuando estás interesado en resumir toda la secuencia en un solo vector de salida.\n",
    "output = lstm(inputs): Se aplica la capa LSTM a los datos de entrada inputs, lo que procesa todas las secuencias en el lote. El resultado se almacena en output.\n",
    "\n",
    "3. Impresión de las Formas de Salida:\n",
    "\n",
    "print(output.shape): Esto imprime la forma de output, que será (32, 4) en este caso. Esto significa que tienes 32 secuencias en el lote, y para cada una de ellas, la capa LSTM produce una representación de 4 dimensiones. \n",
    "\n",
    "4. Creación de una Capa LSTM con return_sequences y return_state:\n",
    "\n",
    "lstm = tf.keras.layers.LSTM(4, return_sequences=True, return_state=True): Aquí se crea otra capa LSTM, pero esta vez se configura para devolver tanto las secuencias completas de salida como el estado final de la memoria y el estado final de transporte (cell state) de la capa LSTM.\n",
    "\n",
    "5. Aplicación de la Capa LSTM a los Datos de Entrada:\n",
    "\n",
    "**whole_seq_output, final_memory_state, final_carry_state = lstm(inputs)**: Esta vez, la capa LSTM se aplica a los datos de entrada inputs, y debido a return_sequences=True, la capa devuelve las secuencias completas de salida en whole_seq_output. Además, debido a return_state=True, la capa también devuelve el estado final de la memoria en final_memory_state y el estado final de transporte en final_carry_state.\n",
    "\n",
    "6. Impresión de las Formas de Salida Adicionales:\n",
    "\n",
    "print(whole_seq_output.shape): Esto imprime la forma de whole_seq_output, que será (32, 10, 4). Esto significa que para cada una de las 32 secuencias en el lote, la capa LSTM produce una secuencia de 10 pasos de tiempo, cada uno con una representación de 4 dimensiones.\n",
    "print(final_memory_state.shape): Esto imprime la forma de final_memory_state, que será (32, 4). Cada una de las 32 secuencias en el lote tiene un estado final de memoria de 4 dimensiones.\n",
    "print(final_carry_state.shape): Esto imprime la forma de final_carry_state, que también será (32, 4). Cada una de las 32 secuencias en el lote tiene un estado final de transporte de 4 dimensiones.\n",
    "\n",
    "En resumen, este ejemplo ilustra cómo utilizar la capa LSTM en TensorFlow para procesar secuencias de datos y cómo configurarla para devolver diferentes tipos de salidas, incluyendo secuencias completas y estados finales. Esto es útil en tareas de procesamiento de secuencias como el análisis de texto o la predicción de series temporales.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe96a7b7-b5c4-42f5-8110-c72fe3266b04",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### ejemplo concreto\n",
    "tf.random.normal([32, 10, 8]): Esto crea un tensor con datos aleatorios utilizando TensorFlow. Ahora desglosemos lo que significa cada dimensión en la forma [32, 10, 8]:\n",
    "\n",
    "32: Representa el tamaño del lote (batch size). En términos simples, imagina que tienes 32 secuencias de datos independientes. Cada una de estas secuencias puede ser, por ejemplo, una serie temporal, un conjunto de características o cualquier tipo de datos secuenciales que quieres procesar de manera simultánea. Esta configuración es común en el aprendizaje profundo para procesar lotes de datos al mismo tiempo, lo que puede acelerar el entrenamiento en hardware optimizado.\n",
    "\n",
    "10: Indica la longitud de cada secuencia. Cada una de las 32 secuencias tiene 10 pasos de tiempo. Los pasos de tiempo representan instantes discretos en el tiempo o puntos en la secuencia. Por ejemplo, si estás trabajando con una serie temporal diaria, cada secuencia tendría datos para 10 días.\n",
    "\n",
    "8: Representa la dimensión de cada paso de tiempo. En cada uno de los 10 pasos de tiempo de cada secuencia, tienes 8 valores o características diferentes. Estos valores pueden ser cualquier cosa, desde datos numéricos hasta características extraídas de una imagen o texto.\n",
    "\n",
    "En resumen, puedes pensar en este tensor [32, 10, 8] como un conjunto de 32 secuencias de datos, cada una con una longitud de 10 pasos de tiempo, y en cada paso de tiempo, tienes 8 características diferentes.\n",
    "\n",
    "En el contexto del aprendizaje profundo y el procesamiento de secuencias, este tipo de datos es muy común. Puedes utilizarlo como entrada para modelos como redes neuronales recurrentes (RNN) o redes neuronales convolucionales 1D (CNN-1D) para tareas como predicción de series temporales, procesamiento de lenguaje natural o cualquier otra tarea que implique datos secuenciales con características multidimensionales.\n",
    "\n",
    "#### Ejemplo de la vida real\n",
    "\n",
    "Claro, aquí tienes una analogía de la vida real para entender mejor el concepto:\n",
    "\n",
    "Imagina que eres el gerente de una cadena de tiendas minoristas y estás analizando las ventas diarias de tus 32 tiendas durante 10 días. Quieres entender cómo diferentes factores, como el clima, los precios y la ubicación, afectan a las ventas.\n",
    "\n",
    "Tamaño del Lote (Batch Size, 32): Representa la cantidad de tiendas que deseas analizar simultáneamente. En este caso, tienes 32 tiendas en diferentes ubicaciones y deseas analizarlas todas juntas para obtener una visión general de cómo van las ventas en tu cadena.\n",
    "\n",
    "Longitud de la Secuencia (10): Cada día es un paso de tiempo en tu análisis. Tienes datos de ventas de cada tienda durante 10 días consecutivos. La longitud de la secuencia es como el período de tiempo que estás observando, en este caso, 10 días.\n",
    "\n",
    "Dimensión de cada Paso de Tiempo (8): En cada día (paso de tiempo), registras 8 valores diferentes que describen las condiciones de ese día. Estos valores pueden incluir cosas como la temperatura, la publicidad realizada, los precios de los productos, la ubicación geográfica, etc.\n",
    "\n",
    "Así que, en resumen, este tensor [32, 10, 8] sería como tener datos de ventas de 32 tiendas durante 10 días, y en cada día tienes 8 características diferentes que describen las condiciones de ese día. Esto te permite analizar cómo las condiciones en diferentes tiendas y días afectan a las ventas de tu cadena minorista, lo que podría ayudarte a tomar decisiones comerciales más informadas.\n",
    "\n",
    "#### explicame esto con un ejemplo:print(output.shape): Esto imprime la forma de output, que será (32, 4) en este caso. Esto significa que tienes 32 secuencias en el lote, y para cada una de ellas, la capa LSTM produce una representación de 4 dimensiones. \n",
    "\n",
    "Claro, aquí tienes una analogía utilizando datos similares a los que se están procesando en la capa LSTM:\n",
    "\n",
    "Imagina que eres un científico que estudia el comportamiento de 32 ratones en un laberinto durante un experimento. Cada ratón se representa como una secuencia de datos con 4 características diferentes. Estas características podrían ser cosas como la distancia recorrida, el tiempo empleado, la cantidad de giros y la velocidad.\n",
    "\n",
    "Tamaño del Lote (Batch Size, 32): Tienes un conjunto de 32 ratones que estás observando al mismo tiempo durante el experimento. Esto es como si tuvieras 32 sujetos de prueba.\n",
    "\n",
    "Forma de Salida (Output Shape, (32, 4)): Cuando aplicas la capa LSTM a los datos de cada ratón, obtienes una representación de 4 dimensiones para cada uno. Esto es similar a obtener un conjunto de 4 valores para cada ratón después de procesar sus datos con la capa LSTM.\n",
    "\n",
    "Entonces, cuando imprimes output.shape, estás viendo la forma de la salida de la capa LSTM después de procesar los datos de todos los ratones en tu experimento. Cada una de las 32 secuencias (ratones) tiene una representación de 4 dimensiones que captura su comportamiento en el laberinto a lo largo del tiempo. Esta información podría ser útil para analizar cómo difieren los ratones en su comportamiento y tomar decisiones basadas en esos patrones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2388ff-d845-4e1f-b436-80bff48b7f17",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## capas optimizar perdida"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec66dc48-8626-40f8-a8a3-248b236aa6d9",
   "metadata": {},
   "source": [
    "En un modelo de deep learning, los conceptos de capas, función de pérdida y optimización son fundamentales. Aquí te explico cada uno:\n",
    "\n",
    "Capas:\n",
    "\n",
    "Un modelo de deep learning se compone de capas, que son básicamente bloques de construcción. Cada capa transforma los datos de entrada de alguna manera, gracias a una serie de parámetros (o pesos) que se aprenden durante el entrenamiento.\n",
    "Hay diferentes tipos de capas, como capas densas (o completamente conectadas), capas de convolución (usadas en el procesamiento de imágenes), capas recurrentes (para secuencias como el texto), entre otras.\n",
    "La estructura de capas en un modelo define su arquitectura. Por ejemplo, una red neuronal convolucional (CNN) para el procesamiento de imágenes tendrá capas de convolución, mientras que una red neuronal recurrente (RNN) para procesamiento de lenguaje natural tendrá capas recurrentes.\n",
    "Función de Pérdida:\n",
    "\n",
    "La función de pérdida, también conocida como función de costo, mide qué tan bien el modelo está realizando su tarea. Es una forma de cuantificar el error entre las predicciones del modelo y los valores reales (etiquetas) durante el entrenamiento.\n",
    "Existen diferentes funciones de pérdida, dependiendo del tipo de tarea. Por ejemplo, la pérdida de entropía cruzada se usa a menudo en problemas de clasificación, mientras que la pérdida de error cuadrático medio es común en problemas de regresión.\n",
    "El objetivo del entrenamiento es minimizar esta función de pérdida, lo que implica mejorar la precisión de las predicciones del modelo.\n",
    "Optimización:\n",
    "\n",
    "La optimización se refiere al proceso de ajustar los parámetros (pesos) del modelo para minimizar la función de pérdida.\n",
    "Este proceso se realiza mediante algoritmos de optimización, siendo el más conocido el Descenso de Gradiente y sus variantes como el Descenso de Gradiente Estocástico (SGD), Adam, RMSprop, etc.\n",
    "Durante la optimización, el algoritmo realiza ajustes iterativos a los pesos de la red, basándose en el gradiente de la función de pérdida. Esto se hace para encontrar la combinación de pesos que resulte en el menor error posible.\n",
    "En resumen, las capas definen la arquitectura del modelo y realizan las transformaciones de datos, la función de pérdida evalúa el rendimiento del modelo, y los algoritmos de optimización ajustan los pesos del modelo para mejorar su rendimiento.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c014b9e-edb5-4b98-b63c-1df79b351309",
   "metadata": {},
   "source": [
    "## que es un tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf42ab5-97d7-47cd-b6c2-39e62b9222b6",
   "metadata": {},
   "source": [
    "Un tensor es una estructura de datos que generaliza escalares, vectores y matrices a dimensiones más altas. En matemáticas y física, un tensor puede representar una variedad de conceptos físicos y geométricos, como tensiones, momentos de inercia, etc., dependiendo de cómo se transforme bajo ciertas operaciones, como rotaciones. En el contexto del aprendizaje profundo y la computación, un tensor es simplemente una matriz multidimensional o un arreglo de números.\n",
    "\n",
    "Aquí hay una desglosación de cómo los tensores se relacionan con estructuras de datos más familiares:\n",
    "\n",
    "Escalar (Tensor de 0-D): Un único número. En términos de tensores, es un tensor de 0 dimensiones.\n",
    "Vector (Tensor de 1-D): Un arreglo de números. Esto es un tensor de 1 dimensión.\n",
    "Matriz (Tensor de 2-D): Una matriz de números, con dos ejes. Esto es un tensor de 2 dimensiones.\n",
    "Tensor de 3-D o superior: A medida que agregamos más ejes, obtenemos tensores de dimensiones más altas. Por ejemplo, los datos de una imagen a color se pueden representar como un tensor de 3-D, donde las dimensiones corresponden a la altura, ancho y canales de color de la imagen.\n",
    "En las bibliotecas de aprendizaje automático como TensorFlow y PyTorch, los tensores son las unidades básicas de datos. Estas bibliotecas están diseñadas para procesar eficientemente tensores grandes, lo que permite modelar y resolver problemas complejos. Los tensores son particularmente importantes en el aprendizaje profundo porque:\n",
    "\n",
    "Manejo de Datos: Permiten manejar grandes conjuntos de datos. Por ejemplo, un conjunto de imágenes puede almacenarse en un tensor de 4 dimensiones: [número de imágenes, altura, ancho, canales de color].\n",
    "Operaciones Vectorizadas: Facilitan operaciones matemáticas eficientes y vectorizadas que son fundamentales en el entrenamiento de redes neuronales.\n",
    "Generalización: Permiten una generalización más allá de las 2-D, lo que es crucial para el aprendizaje automático, donde los datos pueden tener muchas dimensiones (por ejemplo, series de tiempo, señales, imágenes volumétricas, etc.).\n",
    "Gradientes y Backpropagation: En la propagación hacia atrás (backpropagation), los gradientes de una función de pérdida con respecto a los parámetros del modelo se calculan utilizando operaciones tensoriales.\n",
    "En resumen, un tensor es un contenedor flexible para datos numéricos, que permite a los algoritmos de aprendizaje automático escalar con complejidad y tamaño de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3414559-8dbd-4923-b181-44ed1c4121e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
